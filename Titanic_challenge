2020-05-08
By adding "Fare","Embarked" to  RandomForestClassifier(n_estimators=100, max_depth=4, random_state=1) 
And using 'test_data = test_data.fillna(method='ffill')' to fill in test.Fare only
I have received my best result on the first day:
0.78947

2020-05-09
Attempt 01:
1) test_data['Fare'] - another way to fill
test_data[test_data['Fare'].isna()] # checking who was going 'for free'
test_data[150:154] #check his neighbours
My guess is that Mr Thomas had not expensive fare, otherwise the price would be properly recorderd. Filling his ticket with minimal price
test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].min()) #which appears to be Zero

2) test_data['Age'] - adding age becasue it may influence physicall fitness and survival rate
test_data[test_data['Age'].isna()] # checking who has no age
# I do not see system in age omission, fill it with mean
test_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())
train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())
test_data['Age'].hist(); # checking the histogram

3) checking disbalance
print('In our list of', train_data['Survived'].count(), 'passengers', 'only', train_data['Survived'].sum(), 'survived')
print('Disbalance is not strong - survival share',"{:3.1%}".format(train_data['Survived'].sum()/train_data['Survived'].count()) )

In our list of 891 passengers only 342 survived
Disbalance is not strong - survival share 38.4%

# selecting features
features = ["Pclass","Age" ,"Sex", "SibSp", "Parch","Fare","Embarked"]

# work with categories, avoiding dummy trap
y = train_data["Survived"]
X = pd.get_dummies(train_data[features], drop_first=True)
X_test = pd.get_dummies(test_data[features], drop_first=True)

#Let us apply scaller to data
from sklearn.preprocessing import StandardScaler
#numerical fields
numeric = ['Pclass', 'Age', 'SibSp','Parch', 'Fare']
# change scale of numeric fields
scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X) 
X_test = scaler.transform(X_test)

# importing set of metrics
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score  
from sklearn.metrics import precision_score  
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
# 30 percent of train data are going into valid dataset
features_train, features_valid, target_train, target_valid = train_test_split(
    X, y, test_size=0.3, random_state=12345)

print('Train dataset has',  len(features_train), 'entries')
Train dataset has 623 entries
print('Validation dataset has',  len(features_valid), 'entries')
Validation dataset has 268 entries

Looking for params before submission - iterative procedure

for depth in range(1, 16, 1):
    model = RandomForestClassifier(max_depth=depth, n_estimators = 100, random_state=1234)
    model.fit(features_train, target_train)
    predicted_valid = model.predict(features_valid)
    print("max_depth =", depth,  ": ", end='')
    print("F1 for RandomForestClassifier after up-sampling:", end='')
    print("F1:", f1_score(target_valid, predicted_valid))
    print('Area under curve for ROC: ', end='')
    probabilities_valid = model.predict_proba(features_valid)
    probabilities_one_valid = probabilities_valid[:, 1]
    auc_roc = roc_auc_score(target_valid,probabilities_one_valid)
    print(auc_roc)

max_depth = 1 : F1 for RandomForestClassifier after up-sampling:F1: 0.5033112582781457
Area under curve for ROC: 0.8197687728937728
max_depth = 2 : F1 for RandomForestClassifier after up-sampling:F1: 0.6242774566473989
Area under curve for ROC: 0.8234603937728937
max_depth = 3 : F1 for RandomForestClassifier after up-sampling:F1: 0.64
Area under curve for ROC: 0.8262076465201467
max_depth = 4 : F1 for RandomForestClassifier after up-sampling:F1: 0.6775956284153005
Area under curve for ROC: 0.8323603479853481
max_depth = 5 : F1 for RandomForestClassifier after up-sampling:F1: 0.6739130434782609
Area under curve for ROC: 0.8314445970695971
max_depth = 6 : F1 for RandomForestClassifier after up-sampling:F1: 0.6739130434782609
Area under curve for ROC: 0.8349931318681318
max_depth = 7 : F1 for RandomForestClassifier after up-sampling:F1: 0.6844919786096257
Area under curve for ROC: 0.8422619047619049
max_depth = 8 : F1 for RandomForestClassifier after up-sampling:F1: 0.7046632124352331
Area under curve for ROC: 0.8395718864468864
max_depth = 9 : F1 for RandomForestClassifier after up-sampling:F1: 0.7070707070707071
Area under curve for ROC: 0.8432062728937729
max_depth = 10 : F1 for RandomForestClassifier after up-sampling:F1: 0.6995073891625615
Area under curve for ROC: 0.8465544871794871
max_depth = 11 : F1 for RandomForestClassifier after up-sampling:F1: 0.7087378640776699
Area under curve for ROC: 0.8401728479853481
max_depth = 12 : F1 for RandomForestClassifier after up-sampling:F1: 0.7264150943396227
Area under curve for ROC: 0.8413461538461537
max_depth = 13 : F1 for RandomForestClassifier after up-sampling:F1: 0.7047619047619047
Area under curve for ROC: 0.8402586996336996
max_depth = 14 : F1 for RandomForestClassifier after up-sampling:F1: 0.7081339712918661
Area under curve for ROC: 0.8369104853479853
max_depth = 15 : F1 for RandomForestClassifier after up-sampling:F1: 0.6981132075471698
Area under curve for ROC: 0.8338770604395604
  
 Best case is max_depth = 12 : F1 for RandomForestClassifier after up-sampling:F1: 0.7264150943396227 Area under curve for ROC: 0.8413461538461537
 
model = RandomForestClassifier(max_depth=12, n_estimators = 100, random_state=1234)
model.fit(features_train, target_train)
predicted_valid = model.predict(features_valid)

print('Confusion matrix:')
print(confusion_matrix(target_valid, predicted_valid))

Confusion matrix:
[[133  23]
 [ 35  77]]

Test predictions and output as per kaggle requirement

model = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=1234)
#model = GradientBoostingClassifier(n_estimators=100, max_depth=15, random_state=1)

model.fit(X, y)
predictions = model.predict(X_test)

output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})
output.to_csv('my_submission.csv', index=False)
print("Your submission was successfully saved!")




